{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de Lenguaje Natural\n",
    "\n",
    "*MINI-TASK \\#2* \n",
    "\n",
    "# ***Corrector ortográfico de P. Norvig***\n",
    "\n",
    "### **Equipo:**\n",
    "\n",
    "- Burruel Durán Luis Andrés\n",
    "- Giottonini Herrera Enrique Alejandro\n",
    "- Villalba Miranda Jesús Abraham\n",
    "\n",
    "**Fuentes**\n",
    "* [How to Write a Spelling Corrector (Peter Norvig) ](https://norvig.com/spell-correct.html)\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **I. Introducción**\n",
    "\n",
    "En el mundo en el que siempre estamos redactando información, séase mediante la generación de documentos o por la comunicación por medio de mensajes, una de las características más sobresalientes de los editores de texto que utilizamos, es la capacidad de corregir aquellas palabras que escribimos incorrectamente.\n",
    "\n",
    "[Corrector ortográfico ](https://es.wikipedia.org/wiki/Corrector_ortogr%C3%A1fico#:~:text=Un%20corrector%20ortogr%C3%A1fico%20es%2C%20en,al%20usuario%20en%20su%20escritura.)\n",
    " > Un *corrector ortográfico* es una aplicación de software que se utiliza para analizar textos con el fin de detectar y, de forma automática o manual, corregir faltas ortográficas ayudando al usuario en su escritura.\n",
    "\n",
    "### ¿Cómo funciona un corrector ortográfico?\n",
    "Un corrector ortográfico sigue el siguiente proceso:\n",
    " 1. **Identifica la palabra incorrecta**\n",
    "    \n",
    "    Identificamos que una palabra es incorrecta, es decir, no se encuentra dentro de nuestro vocabulario.\n",
    "\n",
    " 2. **Se calculan las palabras a 1, 2 o 3 de distancia**\n",
    "    \n",
    "    Para esto se utiliza el algoritmo de **distancia mínima de edición**, lo que nos ayuda a tener una noción de similaridad entre dos palabras. \n",
    "    \n",
    "    La **distancia mínima de edición** entre dos palabras la podemos definir como el mínimo número de operaciones de edición para transformar una cadena de caracteres (*source*) en otra (*target*).\n",
    "\n",
    "    Las operaciones de edición pueden ser inserción, eliminación y remplazo de un carácter. A estas operaciones se les asigna un peso y basado en este, se obtiene la distancia.\n",
    "\n",
    " 3. **Se filtran los posibles candidatos**\n",
    "    \n",
    "    De las palabras obtenidas en el paso anterior, se filtran los posibles candidatos de manera que se encuentren dentro de nuestro vocabulario.\n",
    "    \n",
    " 4. **Se calcula el más probable en funcion del contexto**\n",
    "\n",
    "    Intentamos encontrar la corrección *c*, de todos los candidatos, de forma que maximize la probabilidad de que *c* es la corrección (palabra) correcta, dada la palabra incorrecta original. Para obtener dicha corrección, nos basamos en nuestro corpus.\n",
    "\n",
    "Durante el resto del documento, explicaremos como funciona nuestra implementación de un corrector ortográfico basada en la libreta realizada por *P. Norvig*. Las secciones las podemos dividir en: II. ¿Cómo funciona?; en donde explicaremos como implementamos el corrector; III. Evaluación y IV. Conclusiones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **II. ¿Cómo funciona?**\n",
    "\n",
    "Comenzamos por importar las librerias que utilizaremos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar un corrector ortográfico, estamos intentando encontrar la corrección $c$, dentro de todos los posibles candidatos, de tal forma que maximize la probabilidad de que $c$ es la corrección correcta, dada la palabra original $w$.\n",
    "\n",
    "$$argmax_{c \\in candidates} P(c|w)$$\n",
    "\n",
    "Por el teorema de Bayes, esta expresión es equivalente a\n",
    "\n",
    "$$argmax_{c \\in candidates} P(c) \\dfrac{P(w|c)}{P(w)}$$\n",
    "\n",
    "Como $P(w)$ es la misma para cualquier candidato $c$, podemos expresarlo de la siguiente manera:\n",
    "\n",
    "$$argmax_{c \\in candidates} P(c) P(w|c)$$\n",
    "\n",
    "Esta expresión la podemos separar en cuatro partes:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `1) Selection Mechanism`\n",
    "\n",
    "---\n",
    "\n",
    "Elegimos el candidato con mayor probabilidad combinada ($argmax$), esto lo vemos en la función `correccion`, con la palabra reservada `max` y el argumento `key`. \n",
    "\n",
    "La función `max` regresa el elemento más grande de un conjunto de elementos y `key` recibe una función con la cual los elementos son comparados.\n",
    "\n",
    "```python\n",
    "def correction(word):\n",
    "    return max(candidates(word), key=P)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `2) Candidate Model`\n",
    "\n",
    "---\n",
    "\n",
    "Generamos un conjunto de candidatos a partir de la palabra. Definimos a la edición simple de una cadena de caracteres como la eliminación, sustitución o inserción de algún caracter en la cadena original. La  función edits1  dada una palabra regresa el conjunto de todas las cadenas de caracteres que se pueden obtener al realizar alguna de las tres operaciones previamente mencionadas en la palabra dada.\n",
    "\n",
    "Por otro lado, la función edits2 obtiene una palabra, y regresa el conjunto de todas las cadenas que se pueden obtener al realizar dos operaciones en dicha palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmñnopqrstuvwxyzáéíóú'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word)+1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in (set(letters)-set(R[0]))]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes+replaces+inserts)\n",
    "\n",
    "def edits2(word): return set(e2 for e1 in edits1(word) for e2 in edits1(e1))-edits1(word)-set(word)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al considerar textos en español, nuestro conjunto de letras (\"letters\") posee ahora 32 símbolos, esto es, las 26 que comparte con el alfabeto inglés, más las cinco vocales con acento, mas el caracter \"ñ\". Así, con una cadena de caracteres de longitud n, podemos obtener n cadenas al eliminar un simbolo de la cadena original, 31n al realizar reemplazos y 32(n+1)-n al insertar símbolos, esto es, existen en total 63n+32 cadenas que están a una distancia igual a 1 de la palabra original."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3) Language Model`: $P(c)$\n",
    "\n",
    "---\n",
    "\n",
    "A partir de un corpus $C$ podemos generar un diccionario sencillo $D$ que contenga todas las palabras separadas por espacios de $C$ y su frecuencia de aparición en $C$. Podemos definir tambien de forma sencilla la probabilidad de una palabra $P(w)$ como la proporción de veces que aparece en $C$.\n",
    "\n",
    "$P(c)$, es decir, la probabilidad que $c$ aparezca en nuestro texto. Para esto contamos el número de veces que cada tipo aparece en nuestro vocabulario.\n",
    "\n",
    "Para esta tarea, utilizamos como *corpus* el libro de *Don Quijote de la Mancha* de *Miguel de Cervantes Saavedra* obtenido de [Project Gutenberg](\"https://www.gutenberg.org/cache/epub/2000/pg2000.txt\").\n",
    "\n",
    "Para obtener nuestro vocabulario `WORDS` se utilizo un procesamiento sencillo de texto, en el que solo nos quedamos con caracteres alfanuméricos `re.findall(r'\\w+', text.lower())` y los convertimos a minúscula `text.lower()`.\n",
    "\n",
    "Una vez obtuvimos nuestro vocabulario, calculamos la frecuencia de cada tipo mediante la función `Counter`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "WORDS = Counter(words(open('quijote.txt', encoding='utf-8').read()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener la probabilidad $P(c)$, se creo una función `P(word, N)` que estima la probabilidad de cada palabra basada en su frecuencia. Donde `N` es la cantidad de palabras de nuestro corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(word, N=sum(WORDS.values())): \n",
    "    return WORDS[word] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinalidad del vocabulario WORDS: 22942\n",
      "Cantidad de palabras del quijote: 381226\n",
      "Palabras más comunes:\n",
      "('que', 20628)\n",
      "('de', 18214)\n",
      "('y', 18189)\n",
      "('la', 10363)\n",
      "('a', 9824)\n",
      "('en', 8242)\n",
      "('el', 8210)\n",
      "('no', 6335)\n",
      "('los', 4748)\n",
      "('se', 4691)\n",
      "Probabilidad de la palabra 'que': 0.0541096357541196\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cardinalidad del vocabulario WORDS: {len(WORDS)}\")\n",
    "print(f\"Cantidad de palabras del quijote: {sum(WORDS.values())}\")\n",
    "print(f\"Palabras más comunes:\")\n",
    "for word in (WORDS.most_common(10)):\n",
    "    print(word)\n",
    "print(f\"Probabilidad de la palabra 'que': {P('que')}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4) Error Model`: $P(w|c)$\n",
    "\n",
    "---\n",
    "\n",
    "La probabilidad de que la palabra $w$ se escriba en un texto cuando el autor quería decir $c$. Por ejemplo, $P(qur|que)$ es relativamente alta, pero $P(queeeexyz|que)$ tendría una probabilidad baja. \n",
    "\n",
    "La razón por la que aplicamos el teoréma de Bayes para seleccionar el elemento con propabilidad más grande $P(c|w)$ a una expresión de la forma $P(c)P(w|c)$ es porque queremos que nuestra corrección no solo dependa de la distancia entre el candidato $c$ y la palabra mal escrita $w$, sino tambien en que tan frecuente (en este caso probable) es haber querido escribir $c$.\n",
    "\n",
    "Este *approach* tambien tiene sus problemas ya que  palabras inusuales en $C$ tendrán un $P(w)$ bajo. Por ejemplo, la palabra \"Arrebol\", que es un tecnisísmo sobre el efecto de la luz en las nubes, al escribirse erroneamente como \"Arebl\" es más probable que sea corregido como \"árbol\" en algún corpus de ciencias de plantas.\n",
    "\n",
    "El otro problema es que palabras $w$ que no existan en $D$ tendrán una probabilidad de 0 y serán corregidas. Para estas dificultades son mitigadas con más datos, y actualmente con otros métodos más complejos.\n",
    "\n",
    "El autor original del código no tenía ***data spellings errors***, es decir, datos con los cuales se pueda asignar reglas a la probabilidad de error. Por ejemplo, si los datos fueran palabras tecleadas por computadora entonces es más probable equivocarse en un carácter en las vecindades de esa tecla.\n",
    "\n",
    "En este caso, se escogio que para el error de modelo la probabilidad de una palabra a una distancia edits 0 es infinitamente más probable que una palabra a distancia edits 1, y a su vez esta es infinitamente más probable que una palabra a distancia edits 2. Así que los candidatos están dados por orden de prioridad:\n",
    "\n",
    "- 1. Palabras a edits 0 (palabra original) si está en el vocabulario.\n",
    "- 2. Palabras a edits 1 en el vocabulario.\n",
    "- 3. Palabras a edits 2 en el vocabulario.\n",
    "- 4. Palabra $w$ aunque no esté en el vocabulario.\n",
    "\n",
    "En este orden de candidatos se regresa aquel que maximize la probabilidad $P(c|w)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word): return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    return known([word]) or known(edits1(word)) or known(edits2(word)) or [word]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **III. Evaluación**\n",
    "\n",
    "Hay 2 evaluaciones, primero pruebas de unidad para asegurar que las funciones regresen lo que esperamos que computen, y pruebas sobre el modelo, donde a partir de un dataset que contiene ejemplos de palabras escritas erroneamente y su corrección podemos evaluar como se desempeña nuestro corrector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_tests():\n",
    "    assert correction(\"kijote\") == \"quijote\"                # replace   \n",
    "    assert correction(\"cabalo\") == \"caballo\"                # insert\n",
    "    assert correction(\"regalooo\") == \"regalo\"               # delete\n",
    "    assert correction(\"manana\") == \"mañana\"                 # acentos\n",
    "    assert correction(\"noche\") == \"noche\"                   # conocida\n",
    "    assert correction(\"computadora\") == \"computadora\"       # desconocida para el Quijote\n",
    "    assert words(\"ESTO es una PRUEba.\") == [\"esto\", \"es\", \"una\", \"prueba\"]\n",
    "    \n",
    "    return 'unit_tests pass'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las pruebas de *\"spelling\"* esperamos como entrada una secuencia de datos de la forma (`right`, `wrong`) donde nosotros comprobamos que nuestra corrección/predicción sobre `wrong` sea `right`, hacemos lo mismo sobre $n$ datos de la misma forma y regresamos la proporción de aciertos y fallas, y la cantidad de tiempo de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelltest(tests, verbose=False):\n",
    "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
    "    import time\n",
    "    start = time.perf_counter()\n",
    "    good, unknown = 0, 0\n",
    "    n = len(tests)\n",
    "    for right, wrong in tests:\n",
    "        w = correction(wrong)\n",
    "        good += (w == right)\n",
    "        if w!= right:\n",
    "            unknown += (right not in WORDS)\n",
    "            if verbose:\n",
    "                print(f'correction({wrong}) => {w} ({WORDS[w]}); expected {right} ({WORDS[right]})')\n",
    "\n",
    "    dt = time.perf_counter() - start\n",
    "    print(f\"{good/n:.0%} of {n} correct ({unknown/n:.0%} unknown) at {n/dt:.0f} words per sec\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de una secuencia de lineas podemos generar un dataset de pruebas para spelltest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Testset(lines):\n",
    "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
    "    return [(right, wrong)\n",
    "            for (right, wrongs) in (line.split(\":\") for line in lines)\n",
    "            for wrong in wrongs.split()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esperamos que las pruebas unitarias pasen los `asserts` sin errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_tests pass\n"
     ]
    }
   ],
   "source": [
    "print(unit_tests())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% of 3 correct (0% unknown) at 12 words per sec\n"
     ]
    }
   ],
   "source": [
    "spelltest(Testset([\"caballo: cabayo cabalo caballio\",]), verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IV. Conclusiones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
